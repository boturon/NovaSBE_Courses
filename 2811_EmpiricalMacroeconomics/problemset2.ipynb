{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem set 2 Empirical Macro\n",
    "## Due date 2nd of May 2019\n",
    "### Nova SBE Francesco Franco\n",
    "In this part of the problem set we will extract the factors from an artificial dataset to have a better comprehension of the principal component analysis used in BEE FAVAR."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PART I"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from numpy import linalg as LA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OUR data are denoted by $X$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create two time series of 15 obserbations by using a dictionary and then feed it in a dataframe\n",
    "data = {'x1':[10,10.4,9.7,9.7,11.7,11,8.7,9.5,10.1,9.6,10.5,9.2,11.3,10.1,8.5],\n",
    "        'x2':[10.7,9.8,10,10.1,11.5,10.8,8.8,9.3,9.4,9.6,10.4,9,11.6,9.8,9.2]}\n",
    "X    = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let us visualize the data, they are on purpose very related\n",
    "\n",
    "plt.figure(figsize=(16,8))\n",
    "plt.subplot(121)\n",
    "plt.xlabel('time')\n",
    "plt.ylabel('x1')\n",
    "plt.grid()\n",
    "plt.plot(Data['x1'])\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.xlabel('time')\n",
    "plt.ylabel('x2')\n",
    "plt.grid()\n",
    "plt.plot(Data['x2'])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let us plot the scatter plot which gives us a different idea of the relationship between the two series\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.xlabel('x1')\n",
    "plt.ylabel('xr2')\n",
    "plt.grid()\n",
    "plt.ylim([7.5,13])\n",
    "plt.xlim([7.5,12.5])\n",
    "\n",
    "plt.scatter(Data['x1'],Data['x2'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1\n",
    "Compute the mean of the two time series and denote it by $\\bar{X}$ (you can use the functions included in python or compute it $N^{-1}\\sum_{i}^{N}x_{i}$ for each $i$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2\n",
    "Compute the variance covariance matrix of the two time series and denote it by $\\Omega$ (again you can use the functions included in python or compute it $N^{-1}(X-\\bar{X})'((X-\\bar{X})$ directly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eigenvalues\n",
    "A $p\\times p$ symemtric, nonsingular matrix, such as the covariance matrix $XX$ may be reduced to a diagonal matrix $S$ by premultiplying and postmultiplying it by a particular orthonormal matrix $\\Lambda$ such that $$\\Lambda'\\Omega\\Lambda=S$$\n",
    "The diagonal elements of $S$ are called the eigenvalues and the columns of $\\Lambda$ are called the eigenvectors (notice that usually $\\Lambda$ is used to denote de eigenvalues matrix but here I switched notation to be consistent with the class notes) ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The eigenvalues may be obtained from the solution of the equation (the characteristic equation, where $|A|$ denotes the determinant of $A$): $$|\\Omega-sI|=0$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3\n",
    "Find the eigenvalues $s_1$ and $s_2$ by solving the characteristic equation $$|\\Omega-sI|=\\begin{vmatrix}\\omega_{11}-s & \\omega_{12}\\\\\n",
    "\\omega_{21} & \\omega_{22}-s\n",
    "\\end{vmatrix}=\\left(\\omega_{11}-s\\right)\\left(\\omega_{22}-s\\right)-\\omega_{21}\\omega_{12}=0$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eigenvectors\n",
    "Now you can find the eigenvectors as follows: find (unnormalized eigenvector)  $t_1$ associated to $s_1$ solves the following equation $$[\\omega -s_1I]t_1=0$$ \n",
    "Which using our matrices is $$\\left[\\Omega-s_{1}I\\right]t_{1}=\\begin{bmatrix}\\omega_{11}-s_{1} & \\omega_{12}\\\\\n",
    "\\omega_{21} & \\omega_{22}-s_{1}\n",
    "\\end{bmatrix}\\begin{bmatrix}t_{11}\\\\\n",
    "t_{21}\n",
    "\\end{bmatrix}=0$$ which gives two equations  $$t_{11}\\left(\\omega_{11}-s_{1}\\right)+\\omega_{12}t_{21}=0$$$$t_{11}\\omega_{21}+t_{21}\\left(\\omega_{22}-s_{1}\\right)=0$$\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To solve normalize $t_{11}=1$ and solve using the first equation $t_{21}$. Finally plug the vector $t_1$ into the normalizing equation to obtain the eigenvector $\\lambda_1$: $$\\lambda_{1}=\\frac{t_{1}}{\\sqrt{t_{1}'t_{1}}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 4\n",
    "Find the two eigenvectors and obtain $$\\Lambda = [\\lambda_1 | \\lambda_2]$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 5\n",
    "Check that the eigenvectors are orthonormals, that is $\\lambda_1'\\lambda_1=1$, $\\lambda_2'\\lambda_2=1$ and $\\lambda_1'\\lambda_2=0$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 6\n",
    "Verify that $\\Lambda'\\Omega\\Lambda=S$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interpretation\n",
    "you are changing the axis coordinates of the point from the blue axis to the red axis. Notice that the first eigenvector (the red axis with the thicker arrow, the thickness is here the value of the eigenvalue) corresonpds to the axis that explain the most the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notice that in this graph in the new axis coordinates\n",
    "# you need to feed the values of the eigenvalues s and the eigenvectors V\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.xlabel('Var1')\n",
    "plt.ylabel('Var2')\n",
    "plt.grid()\n",
    "plt.ylim([7.5,13])\n",
    "plt.xlim([7.5,12.5])\n",
    "\n",
    "#old axis coordinates\n",
    "plt.arrow(10, 10, 0, 1, head_width=0.05, length_includes_head=True, head_length=0.1,linewidth=2,color='b')\n",
    "plt.arrow(10, 10, 1, 0, head_width=0.05, length_includes_head=True, head_length=0.1, color='b',linewidth=1)\n",
    "\n",
    "#new axis coordinates\n",
    "plt.arrow(10, 10, V[0,0], V[1,0], head_width=0.15, length_includes_head=True, head_length=0.1, color='r',linewidth=s[0])\n",
    "plt.arrow(10, 10, V[0,1], V[1,1], head_width=0.05, length_includes_head=True, head_length=0.1, color='r',linewidth=s[1])\n",
    "\n",
    "\n",
    "plt.scatter(Data['Var1'],Data['Var2'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 7\n",
    "Compute the factors $F_t = \\Lambda X_t$ and plot them"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PART II"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our code to reproduce BEE, we of course obtain the principal components more rapidely by using linear algebra routines that compute the eigenvectors efficiently."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1\n",
    "Notice that in the identification of the monetary policy shock we use a cholesky decomposition. What is that? Remember that the SVAR identification occurs by finding a $A(0)$ that relates the innovations of the VAR with the structural shocks of the SVAR $$\\eta_t = A(0)\\epsilon_t$$\n",
    "now as usual we have the variance from the innovations $\\hat{\\Omega_t}$. Then $$\\hat{\\Omega_t}= A(0)'\\epsilon_t'\\epsilon_t A(0)$$. In the Blanchard and Quah identification we had assumed that that the structural shock had unit variance, here we assume that the diagonal of $A(0)$ is composed by 1. We can do that because we assume that the standard deviation of the monetary policy shock is the standard deviation of the federa fund rate.\n",
    "Change in the code the standard deviation of the monetary policy shock (double it). how do the impulse response change?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2*\n",
    "Obtain the IRF to a monetary policy shock estimating the FAVAR with 4 and 5 factors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
